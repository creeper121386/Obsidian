{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numpy.lib.user_array as UsrArry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def raise_err(func):\n",
    "    def wrapper(self, other):\n",
    "        if self.need_grad:\n",
    "            raise RuntimeError(\n",
    "                'Tensor in graph don\\'t support in-place operation.')\n",
    "        return func(self, other)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Tensor(UsrArry.container):\n",
    "    def __init__(self, data, dtype=None, copy=True, need_grad=False, upper_nodes=None, bak_nodes=None, grad=None):\n",
    "        '''\n",
    "        paramsters:\n",
    "\n",
    "        - data: must be a list or other iterable object.\n",
    "        - upper_nodes: the upper computational node of this Tensor.\n",
    "        - bak_nodes: the computational node in the downstream.\n",
    "        - grad: the grad of this This node.\n",
    "        - need_grad: need grad or not.\n",
    "        - cpt_func: the computation to get the current Tensor node.\n",
    "\n",
    "        In a computational graph, a Tensor node looks like:\n",
    "\n",
    "            Forward: Tensor.bak_nodes ->(cpt_func)-> Tensor --> Tensor.upper_nodes\n",
    "            Backward: Tensor.bak_nodes <-(grad_func)<- Tensor\n",
    "        '''\n",
    "\n",
    "        UsrArry.container.__init__(self, data, dtype=None, copy=True)\n",
    "        # super(Tensor, self).__init__(data, dtype=None, copy=True)\n",
    "\n",
    "        self.cpt_name = None\n",
    "        self.need_grad = need_grad\n",
    "        self.grad = grad\n",
    "        # self.upper_nodes = upper_nodes\n",
    "        self.bak_nodes = bak_nodes\n",
    "\n",
    "    def _add_to_graph(self, upper_nodes, name, other=None):\n",
    "        if not isinstance(upper_nodes, Tensor):\n",
    "            raise TypeError(\n",
    "                'Input must be a Tensor, but got type {}'.format(type(upper_nodes)))\n",
    "        # self.upper_nodes = upper_nodes\n",
    "\n",
    "        upper_nodes.need_grad = True\n",
    "        upper_nodes.cpt_name = name\n",
    "        upper_nodes.bak_nodes = (self, ) if not other else (self, other)\n",
    "\n",
    "        # if isinstance(other, Tensor) and other.need_grad:\n",
    "        #     other.upper_nodes = upper_nodes\n",
    "\n",
    "    def __str__(self):\n",
    "        return super().__str__() + ', dtype={}, size={}\\n'.format(self.dtype, self.shape)\n",
    "\n",
    "    def __abs__(self):\n",
    "        res = super().__abs__()\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'abs')\n",
    "        return res\n",
    "\n",
    "    def __neg__(self):\n",
    "        res = super().__neg__()\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'neg')\n",
    "        return res\n",
    "\n",
    "    def __add__(self, other):\n",
    "        res = super().__add__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'add', other)\n",
    "        return res\n",
    "\n",
    "    __radd__ = __add__\n",
    "\n",
    "    @raise_err\n",
    "    def __iadd__(self, other):\n",
    "        return super().__iadd__(other)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        res = super().__sub__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'sub', other)\n",
    "        return res\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        res = super().__rsub__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'sub', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __isub__(self, other):\n",
    "        return super().__isub__(other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = super().__mul__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mul', other)\n",
    "        return res\n",
    "\n",
    "    __rmul__ = __mul__\n",
    "\n",
    "    @raise_err\n",
    "    def __imul__(self, other):\n",
    "        return super().__imul__(other)\n",
    "\n",
    "    def __div__(self, other):\n",
    "        res = super().__div__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'div', other)\n",
    "        return res\n",
    "\n",
    "    def __rdiv__(self, other):\n",
    "        res = super().__rdiv__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'div', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __idiv__(self, other):\n",
    "        return super().__idiv__(other)\n",
    "\n",
    "    def __mod__(self, other):\n",
    "        res = super().__mod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mod', other)\n",
    "        return res\n",
    "\n",
    "    def __rmod__(self, other):\n",
    "        res = super().__rmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mod', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __imod__(self, other):\n",
    "        return super().__imod__(other)\n",
    "\n",
    "    def __divmod__(self, other):\n",
    "        res = super().__divmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'divmod', other)\n",
    "        return res\n",
    "\n",
    "    def __rdivmod__(self, other):\n",
    "        res = super().__rdivmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'rdivmod', other)\n",
    "        return res\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        res = super().__pow__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'pow', other)\n",
    "        return res\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        res = super().__rpow__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'pow', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __ipow__(self, other):\n",
    "        return super().__ipow__(other)\n",
    "    \n",
    "    def __matmul__(self, other):\n",
    "        return super().__matmul__(other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(np.ones((3, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for //: 'Tensor' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-bfef54461549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'Tensor' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "a = Tensor([1, 2, 3], need_grad=True)\n",
    "b = Tensor([3, 2, 1])\n",
    "c = ( a // b )\n",
    "\n",
    "print(c)\n",
    "print(c.cpt_name)\n",
    "print(c.bak_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([1, 2, 3]), dtype=int64, size=(3,)\n",
      "\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tmp = c.bak_nodes[0].bak_nodes[0].bak_nodes[0]\n",
    "print(tmp)\n",
    "print(tmp.cpt_name)\n",
    "print(tmp.bak_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
