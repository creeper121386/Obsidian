{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numpy.lib.user_array as UsrArry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __rtruediv__(self, other):\n",
    "        return self.data / other \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A(8)\n",
    "2/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def raise_err(func):\n",
    "    def wrapper(self, other):\n",
    "        if self.need_grad:\n",
    "            raise RuntimeError(\n",
    "                'Tensor in graph don\\'t support in-place operation.')\n",
    "        return func(self, other)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Tensor(UsrArry.container):\n",
    "    def __init__(self, data, dtype=None, copy=True, need_grad=False, upper_nodes=None, bak_nodes=None, grad=None):\n",
    "        '''\n",
    "        paramsters:\n",
    "\n",
    "        - data: must be a list or other iterable object.\n",
    "        - upper_nodes: the upper computational node of this Tensor.\n",
    "        - bak_nodes: the computational node in the downstream.\n",
    "        - grad: the grad of this This node.\n",
    "        - need_grad: need grad or not.\n",
    "        - cpt_func: the computation to get the current Tensor node.\n",
    "\n",
    "        In a computational graph, a Tensor node looks like:\n",
    "\n",
    "            Forward: Tensor.bak_nodes ->(cpt_func)-> Tensor --> Tensor.upper_nodes\n",
    "            Backward: Tensor.bak_nodes <-(grad_func)<- Tensor\n",
    "        '''\n",
    "\n",
    "        UsrArry.container.__init__(self, data, dtype=None, copy=True)\n",
    "        # super(Tensor, self).__init__(data, dtype=None, copy=True)\n",
    "\n",
    "        self.cpt_name = None\n",
    "        self.need_grad = need_grad\n",
    "        self.grad = grad\n",
    "        # self.upper_nodes = upper_nodes\n",
    "        self.bak_nodes = bak_nodes\n",
    "\n",
    "    def _add_to_graph(self, upper_nodes, name, other=None):\n",
    "        if not isinstance(upper_nodes, Tensor):\n",
    "            raise TypeError(\n",
    "                'Input must be a Tensor, but got type {}'.format(type(upper_nodes)))\n",
    "        # self.upper_nodes = upper_nodes\n",
    "\n",
    "        upper_nodes.need_grad = True\n",
    "        upper_nodes.cpt_name = name\n",
    "        upper_nodes.bak_nodes = (self, ) if not other else (self, other)\n",
    "\n",
    "        # if isinstance(other, Tensor) and other.need_grad:\n",
    "        #     other.upper_nodes = upper_nodes\n",
    "\n",
    "    def __str__(self):\n",
    "        return super().__str__() + ', dtype={}, size={}\\n'.format(self.dtype, self.shape)\n",
    "\n",
    "    def __abs__(self):\n",
    "        res = super().__abs__()\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'abs')\n",
    "        return res\n",
    "\n",
    "    def __neg__(self):\n",
    "        res = super().__neg__()\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'neg')\n",
    "        return res\n",
    "\n",
    "    def __add__(self, other):\n",
    "        res = super().__add__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'add', other)\n",
    "        return res\n",
    "\n",
    "    __radd__ = __add__\n",
    "\n",
    "    @raise_err\n",
    "    def __iadd__(self, other):\n",
    "        return super().__iadd__(other)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        res = super().__sub__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'sub', other)\n",
    "        return res\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        res = super().__rsub__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'sub', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __isub__(self, other):\n",
    "        return super().__isub__(other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = super().__mul__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mul', other)\n",
    "        return res\n",
    "\n",
    "    __rmul__ = __mul__\n",
    "\n",
    "    @raise_err\n",
    "    def __imul__(self, other):\n",
    "        return super().__imul__(other)\n",
    "\n",
    "    def __div__(self, other):\n",
    "        res = super().__div__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'div', other)\n",
    "        return res\n",
    "\n",
    "    def __rdiv__(self, other):\n",
    "        res = super().__rdiv__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'div', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __idiv__(self, other):\n",
    "        return super().__idiv__(other)\n",
    "\n",
    "    def __mod__(self, other):\n",
    "        res = super().__mod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mod', other)\n",
    "        return res\n",
    "\n",
    "    def __rmod__(self, other):\n",
    "        res = super().__rmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'mod', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __imod__(self, other):\n",
    "        return super().__imod__(other)\n",
    "\n",
    "    def __divmod__(self, other):\n",
    "        res = super().__divmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'divmod', other)\n",
    "        return res\n",
    "\n",
    "    def __rdivmod__(self, other):\n",
    "        res = super().__rdivmod__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'rdivmod', other)\n",
    "        return res\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        res = super().__pow__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'pow', other)\n",
    "        return res\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        res = super().__rpow__(other)\n",
    "        if self.need_grad:\n",
    "            self._add_to_graph(res, 'pow', other)\n",
    "        return res\n",
    "\n",
    "    @raise_err\n",
    "    def __ipow__(self, other):\n",
    "        return super().__ipow__(other)\n",
    "    \n",
    "    def __matmul__(self, other):\n",
    "        return super().__matmul__(other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([1, 2, 3]), dtype=int64, size=(3,)\n",
      "\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tmp = c.bak_nodes[0].bak_nodes[0].bak_nodes[0]\n",
    "print(tmp)\n",
    "print(tmp.cpt_name)\n",
    "print(tmp.bak_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
